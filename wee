import requests
import re
import pandas as pd

url = "https://api.proxy.datadog/api/v2/spans/events/search"

payload = {
    "data": {
        "attributes": {
            "filter": {
                "query": "service:ttk-service-bla",
                "from": "now-15m",
                "to": "now",
            },
            "page": {"limit": 100},
            "sort": "timestamp"
        },
        "type": "search_request"
    }
}

headers = {
    "DD-API-KEY": "org-...",
    "DD-APPLICATION-KEY": "org-...",
    "Content-Type": "application/json"
}

response = requests.post(url, json=payload, headers=headers)

# =========================================================
# EXTRAÇÃO DE TODOS OS CAMPOS USANDO REGEX
# =========================================================
raw_text = response.text

# Expressões Regex para os campos existentes
status_codes = re.findall(r'"status_code"\s*:\s*"(\d+)"', raw_text)
messages = re.findall(r'"mensagem"\s*:\s*"([^"]+)"', raw_text)

# Expressões Regex para os novos campos
resource_names = re.findall(r'"resource_name"\s*:\s*"([^"]+)"', raw_text)
paths = re.findall(r'"path"\s*:\s*"([^"]+)"', raw_text)
dates = re.findall(r'"date"\s*:\s*"([^"]+)"', raw_text)
funcionais = re.findall(r'"funcional"\s*:\s*"([^"]+)"', raw_text)


rows = []

# =========================================================
# LÓGICA DE FILTRAGEM E CRIAÇÃO DE LINHAS (Rows)
# =========================================================

# Para garantir a extração mais robusta, você deve primeiro identificar
# o campo que tem a MAIOR frequência (status_codes, geralmente)
# e garantir que as outras listas tenham o mesmo número de elementos ou usar 
# uma correspondência baseada em um índice comum (que é complexo e não
# garantido por regex simples).
# Vamos assumir que os eventos estão alinhados e usar o mínimo.

min_len = min(
    len(status_codes),
    len(resource_names),
    len(paths),
    len(dates),
    len(funcionais)
)

print(f"\nNúmero de eventos completos (mínimo de todas as listas): {min_len}")

# Iterar apenas até o tamanho da menor lista para garantir que todos os campos existam
for i in range(min_len):
    rows.append({
        "status_code": status_codes[i],
        "resource_name": resource_names[i],
        "path": paths[i],
        "date": dates[i],
        "funcional": funcionais[i]
    })

# =========================================================
# GERAÇÃO DO DATAFRAME E ARQUIVO FINAL
# =========================================================
df = pd.DataFrame(rows)

# O DataFrame 'df' agora contém SOMENTE as linhas onde todos os 6 valores foram encontrados.

df.to_excel("resultado_completo_filtrado.xlsx", index=False)

print("\n### DataFrame com Linhas Preenchidas (6 Colunas) ###")
print(df.head())
print(f"\nTotal de linhas no DataFrame final: {len(df)}")
print("\nArquivo gerado: resultado_completo_filtrado.xlsx")
